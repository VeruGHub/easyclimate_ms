---
title: "The easyclimate R package: easy access to high-resolution daily climate data for Europe"

# subtitle: "Short title: easyclimate R package"

author: "Verónica Cruz-Alonso (ORCID: 0000-0002-0642-036X) ^1,2^ §, 
    Christoph Pucher (ORCID: 0000-0002-9269-1907) ^3^ §, 
    Sophia Ratcliffe (ORCID: 0000-0001-9284-7900) ^4^,
    Paloma Ruiz-Benito (ORCID: 0000-0002-2781-5870) ^2^,
    Julen Astigarraga (ORCID: 0000-0001-9520-3713) ^2^,
    Mathias Neumann (ORCID: 0000-0003-2472-943X) ^3^
    Francisco Rodríguez-Sánchez (ORCID: 0000-0002-7981-1599) ^5,6^"

# date: `r Sys.Date()`

output:
  bookdown::word_document2:
    fig_caption: yes
    fig_width: 7
    fig_height: 7
    df_print: kable
    keep_md: no
    number_sections: no
    toc: no
    reference_docx: Word_template.docx
    
bibliography: 
  - references.bib
  - knitcitations.bib
csl: journal-of-vegetation-science.csl
---

^1^ Department of Landscape Architecture, Graduate School of Design, Harvard University, USA

^2^ Grupo de Ecología Forestal y Restauración (FORECO), Universidad de Alcalá, Spain

^3^ Boku

^4^ National Biodiversity network

^5^ Departamento de Biología Vegetal y Ecología, Universidad de Sevilla, Spain.

^6^ Estación Biológica de Doñana, Consejo Superior de Investigaciones Científicas, Spain.

§ These authors share the first-author position.

Correspondence:

Verónica Cruz-Alonso, Harvard University, Cambridge, MA, USA. Email: [veronica.cral\@gmail.com](mailto:veronica.cral@gmail.com){.email}

# FUNDING INFORMATION

VCA was supported by the Real Colegio Complutense Postdoctoral Fellowship 2020. FRS was supported by the VI Plan Propio de Investigación of Universidad de Sevilla (VI PPIT-US).

# ABSTRACT

Write your abstract here (200 WORDS MAXIMUM)

*Keywords*: R package, climate, Europe, reproducibility, cloud-optimised geotiffs, (8-12 KEYWORDS)

```{r setup, include=FALSE, cache=FALSE, message = FALSE}
library("knitr")
### Chunk options: see http://yihui.name/knitr/options/ ###
## Text results
opts_chunk$set(echo = TRUE, warning = TRUE, message = FALSE, out.width = "100%")
## Code decoration
opts_chunk$set(tidy = TRUE, comment = NA, highlight = TRUE)
## Cache
opts_chunk$set(cache = TRUE, cache.path = "output/cache/")
## Plots
opts_chunk$set(fig.path = "output/figures/", dpi = 300)
```

# INTRODUCTION

In recent decades there has been an increasing demand for harmonized climatic data at wide spatial scales and spanning long temporal periods (e.g. for the study of the effects of climate change on vegetation, [@Ruiz-Benito2020]). Here we present *easyclimate* [@easyclimatepkg]*,* a software package (available from the Comprehensive R Archive Network, CRAN: [\<https://cran.r-project.org/package\>](https://cran.r-project.org/package=sf)=easyclimate) to download and process climate data with R [@R_Core_Team_2021]. *easyclimate* has been developed to facilitate the downloading and processing of high-resolution (1 km\^2) daily climate data (precipitation, minimum and maximum temperatures) for Europe. Data are currently available from 1950 to 2020 and hosted at [University of Natural Resources and Life Sciences, Vienna, Austria](https://boku.ac.at/en/wabo/waldbau/wir-ueber-uns/daten). This climatic dataset was originally built by Moreno & Hasenauer [@moreno2016spatial] and further developed by W. Rammer, C. Pucher & M. Neumann [cite the document with the updates here?]. The climatic layers are generated by downscaling data from [WorldClim](https://worldclim.org/data/worldclim21.html#) [@fick_worldclim_2017] and [E-Obs](https://surfobs.climate.copernicus.eu/dataaccess/access_eobs.php#datafiles) [@cornes_ensemble_2018]. For this R package we implemented Cloud-Optimised Geotiffs (<https://www.cogeo.org>) so users can obtain daily climate data for thousands of sites and days within minutes, without having to download huge rasters.

# FUNCTIONALITY

The main function in *easyclimate* is *get_daily_climate*, which extracts daily climate data for a given set of coordinates (points or polygons) and a given period of days or years (see examples in *get_daily_climate* [help page](https://verughub.github.io/easyclimate/reference/get_daily_climate.html), and the vignettes [Analysing the climate at spatial points for a given period](https://verughub.github.io/easyclimate/articles/points-df-mat-sf.html) and [Analysing the climate of an area for a given period](https://verughub.github.io/easyclimate/articles/polygons-raster.html)). The output can be either a data.frame (\@ref(tab:Table-1)) or a (multilayer) `SpatRaster` object (\@ref(fig:Fig-1) with daily climatic values for each point or polygon.

For example, to obtain precipitation data for a single site between 1\^st and 3\^rd of January 2001:

```{r example df}
library(easyclimate)

coords <- data.frame(lon = -5.36, lat = 37.40)

precip <- get_daily_climate(coords, 
                          period = "2001-01-01:2001-01-03", 
                          climatic_var = "Prcp")
```

And to obtain a multilayer raster with values of maximum temperature for two days (1\^st January and 7\^th August 2012) for a region delimited by a polygon:

```{r example raster}
library(terra)

coords_poly <- vect("POLYGON ((-4.5 41, -4.5 40.5, -5 40.5, -5 41))")

ras_tmax <- get_daily_climate(
  coords_poly,
  period = c("2012-01-01", "2012-08-07"),
  climatic_var = "Tmax",
  output = "raster" 
  )

```

By design, *easyclimate* yields tidy datasets [@wickham_tidy_2014] that facilitate calculation of alternative climatic variables and indices following the [tidyverse](https://www.tidyverse.org/) philosophy. In the next example we download daily climatic data for a five-year period for a specific location and store them in a dataframe.

```{r tidy dataset}

library(dplyr)

coords <- data.frame(lon = -4.88, lat = 40.82)

prec <- get_daily_climate(coords, 
                          period = 2010:2015,
                          climatic_var = "Prcp")  

tmin <- get_daily_climate(coords, 
                          period = 2010:2015,
                          climatic_var = "Tmin")

tmax <- get_daily_climate(coords, 
                          period = 2010:2015,
                          climatic_var = "Tmax")

daily <- prec %>% 
  full_join(tmin %>% select(ID_coords, date, Tmin)) %>% 
  full_join(tmax %>% select(ID_coords, date, Tmax)) %>% 
  mutate(Tmean = (Tmin + Tmax) / 2, 
         date = as.Date(date),
         month = format(date, format = "%m"),
         year = format(date, format = "%Y"))

```

To calculate average temperatures and accumulated precipitation by site or time period (\@ref(tab:Table-2)) we can use `group_by` and `summarise` from `dplyr`, or `by` and `aggregate` from base R:

```{r}

yearclimate <- daily %>% 
  group_by(year) %>% 
  summarise(Tmin.year = mean(Tmin),
            Tmean.year = mean(Tmean),
            Tmax.year = mean(Tmax),
            Prcp.year = sum(Prcp))
```

The results of the package *easyclimate* can be used directly or serve as input to calculate climatic indices with other packages, such as ClimInd [@climind] or SPEI [@spei].

# *easyclimate* advantages

The climatic data are available for download as GeoTIFF raster layers in a public FTP server (<ftp://palantir.boku.ac.at/Public/ClimateData/>). For querying climate data from large areas, it is recommended to download the raster layers and extract the data in our local computer or server (e.g. using the `extract` function from `terra` R package, @terra), so as not to saturate the FTP server. But for small to reasonable areas (e.g. less than 10000 sites or 10000 km\^2), the cloud-optimised geotiff technology implemented in *easyclimate* not only does the task much easier, but also can save significant time.

In the next example we download daily precipitation data for one year in an area of *ca*. 100 km\^2 using the traditional (i.e. raster downloading and local extraction) and the *easyclimate* method. While the local download and extraction took 9 minutes in a laptop with good internet connection, *easyclimate* only took 10 seconds to obtain the same data. Furthermore, with *easyclimate* we avoid downloading large rasters (several GB for each year). Thus, *easyclimate* becomes even more convenient if we are interested in climate data for different years.

```{r eval=FALSE, include=FALSE}

library(terra)

# Method 1: Raster downloading and local data extraction

coords_poly <- vect("POLYGON ((-5.039 40.913, -4.919 40.913, -4.918 40.825, -5.039 40.825))")

raster.url <- "ftp://palantir.boku.ac.at/Public/ClimateData/v3/AllDataRasters/prec/DownscaledPrcp2010.tif"

options(timeout = max(10000, getOption("timeout")))

system.time({
  download.file(raster.url, destfile = "prcp2010.tif")
  prcp2010.ras <- terra::rast("prcp2010.tif") 
  prcp2010.data <- terra::extract(prcp2010.ras, coords_poly, xy = TRUE)
})

```

```{r eval=FALSE, include=FALSE}

# Method 2: Obtain the same data using easyclimate

system.time(
  raster2 <- get_daily_climate(
    coords_poly,
    period = 2010,
    climatic_var = "Prcp"
  )
)

```

# APPLICATIONS IN PLANT SCIENCES

Daily climate data are required for many ecological research questions and applications, including the study of the effects of late-spring frosts, heat waves, or dry periods on plant performance. However, accessing and processing such daily climate data is often cumbersome. Even more if harmonized data are required at large spatial scales.

In the next example we show how we can easily calculate the number of spring days with freezing temperatures (below zero), and the mean minimum temperature reached over several years (\@ref(tab:Table-2); see ["Calculating basic climatic indices with data from easyclimate"](Calculating%20basic%20climatic%20indices%20with%20data%20from%20easyclimate) vignette for other examples).

```{r}

spring.months <- c("03","04","05") # March to May

springfrost <- daily %>% 
  mutate(year = factor(year)) %>% 
  filter(month %in% spring.months) %>% 
  mutate(event = ifelse(Tmin < 0, 1, 0)) %>% 
  group_by(year) %>% 
  mutate(n_frost = sum(event)) %>% 
  filter(event == 1) %>% 
  group_by(ID_coords, year, n_frost) %>% 
  summarise(Tmin_frost_avg = mean(Tmin)) 

```

By providing high-resolution (1-km) daily climate data with large temporal (currently 1950-2020) and spatial extent (longitude between -40.5 and 75.5, latitude between 25.25 and 75.5), *easyclimate* can be a useful tool with multiple aplications in forestry, ecological and vegetation studies all over Europe.

# ACKNOWLEDGEMENTS

On the shoulders of giants.

# AUTHOR CONTRIBUTIONS

Please, complete this sheet with your contribution: <https://docs.google.com/spreadsheets/d/1RfrZkTbl3aaQ0M_j6qH5y4dEmvi-U3xS68qHSkEcm3s/edit#gid=0>

Then, the contribution statement will be wrote automatically.

Use CREDIT taxonomy of author contributions: <https://rollercoaster.shinyapps.io/tenzing/>

# DATA AVAILABILITY STATEMENT

The climate datasets are publicly available at <ftp://palantir.boku.ac.at/Public/ClimateData/>. The easyclimate R package is available on CRAN (**url**) and GitHub (<https://github.com/VeruGHub/easyclimate>).

# REFERENCES

::: {#refs}
:::

\newpage

# Table 1

```{r Table-1, echo=FALSE}
kable(precip[, -1], caption = "Daily precipitation (Prcp; mm) for a given point obtained with easyclimate")
```

\newpage

# Figure 1

```{r Fig-1, echo=FALSE, fig.cap="A multilayer raster of maximum temperature values for a given polygon in two different days of the year"}

par(mfrow = c(1, 2))
terra::plot(ras_tmax, 1, col = rev(heat.colors(20)), type = "continuous", 
            smooth = TRUE, range = c(10, 35), legend = FALSE, 
            mar=c(4, 2, 4, 2), main = "January 1 2012")
terra::plot(ras_tmax, 2, col = rev(heat.colors(20)), type = "continuous", 
            smooth = TRUE, range = c(10, 35), 
            mar = c(4, 1, 4, 3), main = "August 7 2012")

```

\newpage

# Table 2

```{r Table-2, echo=FALSE}
kable(yearclimate, digits = 1, caption = "Average climatic values for a given point extracted with easyclimate")
```

\newpage

# Table 3

```{r Table-3, echo=FALSE}
kable(springfrost[, -1], caption = "No. of days with temperature below zero in spring (n_frost) and mean minimum temperature reached (Tmin_frost_avg) extracted with easyclimate")
```
